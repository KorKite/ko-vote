{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412c8890-3ab7-4ab0-8fbf-178a71e509ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import deepsnap\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from deepsnap.hetero_gnn import forward_op\n",
    "from deepsnap.hetero_graph import HeteroGraph\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81892ae7-cf2a-48b6-8b7f-9b6305a824b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './data/graph/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d4ecf6-efc9-4dfc-97b8-c020f2bee320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(fname):\n",
    "    return pickle.load(open(base_path + fname, 'rb'))\n",
    "\n",
    "def save_tensor(data,fname):\n",
    "    pickle.dump(data, open(fname, 'wb'))\n",
    "\n",
    "def compare_date(source, target):\n",
    "    s_y, s_m, s_d = source.split(\"-\")\n",
    "    t_y, t_m, t_d = target.split(\"-\")\n",
    "    \n",
    "    s_date = datetime.date(int(s_y), int(s_m), int(s_d))\n",
    "    t_date = datetime.date(int(t_y), int(t_m), int(t_d))\n",
    "\n",
    "    return int(s_date < t_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a7141f-7a50-4d1b-8cdb-fc9ed45a907b",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda0909-e278-4ca0-8756-778092c672fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill = pd.read_csv('./data/final_bill.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2a0a7-8605-4520-a810-6234b3434b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_tweet = pd.read_csv('./data/proceseed_bh_tweets.tsv', sep='\\t', dtype={'id':str})\n",
    "new_bh_tweet = pd.DataFrame(bh_tweet.groupby('date')['id'].apply(lambda x: ','.join(x)))\n",
    "new_bh_tweet['id'] = pd.DataFrame(bh_tweet.groupby('date')['id'].apply(lambda x: ' '.join(x)))\n",
    "new_bh_tweet = new_bh_tweet.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e70b2b-4df7-4c44-bee8-115d0c1558a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "member = pd.read_csv('./data/final_cgppl.csv')\n",
    "votes = pd.read_csv('./data/final_votes_21.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c7503d-3bf1-44a1-ae48-2179279ba193",
   "metadata": {},
   "source": [
    "# Load Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db6a9e-760e-4d34-86f0-c4c6d00f49c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_edges = load_pickle('bill_edges.edge_index')\n",
    "mem_mem_edges = load_pickle('mem_mem_edges.edge_index')\n",
    "\n",
    "bh_edges = load_pickle('bh_edges.edge_index')\n",
    "bh_bill_edges = load_pickle('bh_bill_edges.edge_index')\n",
    "bh_mem_edges = load_pickle('bh_mem_edges.edge_index')\n",
    "mem_bill_edges = load_pickle('mem_bill_edges.edge_index')\n",
    "bill_bh_edges = load_pickle('bill_bh_edges.edge_index')\n",
    "\n",
    "bill_weights = load_pickle('bill_weights.edge_attr')\n",
    "mem_mem_weights = load_pickle('mem_mem_weights.edge_attr')\n",
    "bh_weights = load_pickle('bh_weights.edge_attr')\n",
    "bh_bill_weights = load_pickle('bh_bill_weights.edge_attr')\n",
    "bh_mem_weights = load_pickle('bh_mem_weights.edge_attr')\n",
    "mem_bill_weights = load_pickle('mem_bill_weights.edge_attr')\n",
    "bill_bh_weights = load_pickle('bill_bh_weights.edge_attr')\n",
    "\n",
    "bill_emb = load_pickle('bill_emb.x')\n",
    "mem_emb = load_pickle('mem_feat.x')\n",
    "bh_tweet_feat = load_pickle('bh_tweet_feat.x')\n",
    "\n",
    "bill_mem_vote = load_pickle('bill_mem_vote.y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88829c33-e5e1-462b-9cb8-52362fc2eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please do not change the following parameters\n",
    "args = {\n",
    "    'device': torch.device('cuda:1' if torch.cuda.is_available() else 'cpu'),\n",
    "    'hidden_size': 64,\n",
    "    'epochs': 100,\n",
    "    'weight_decay': 1e-5,\n",
    "    'lr': 0.003,\n",
    "    'attn_size': 64,\n",
    "    'batch_size': 128,\n",
    "    'output_dim': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b2e21c-6d05-4ae7-af26-68f5b9cdf5f3",
   "metadata": {},
   "source": [
    "# DateSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6175e634-e8d4-4d57-bf1f-15b0b6f131dc",
   "metadata": {},
   "source": [
    "## BIll mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd9a1d-d5b1-4772-87bb-e3a808e2faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = '2021-06-01'\n",
    "train_mask = [compare_date(source_date, target_date) for source_date in bill['VOTE_DATE'].values]\n",
    "train_mask = torch.LongTensor(train_mask)\n",
    "print(\"# train\", train_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a07a02d-1be5-4de0-b429-2da2de87796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = '2021-08-01'\n",
    "valid_mask = [compare_date(source_date, target_date) for source_date in bill['VOTE_DATE'].values]\n",
    "valid_mask = torch.LongTensor(valid_mask)\n",
    "valid_mask = valid_mask - train_mask\n",
    "print(\"# valid\", valid_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54776fc0-971d-461f-bf7d-bf298f6a8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = '2021-12-01'\n",
    "test_mask = [compare_date(source_date, target_date) for source_date in bill['VOTE_DATE'].values]\n",
    "test_mask = torch.LongTensor(test_mask)\n",
    "test_mask = test_mask - valid_mask - train_mask\n",
    "print(\"# test\", test_mask.sum(), torch.unique(test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42505433-fefd-440d-a78a-76f6d6b0189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_train_mask = train_mask.nonzero().view(-1).long()\n",
    "bill_valid_mask = valid_mask.nonzero().view(-1).long()\n",
    "bill_test_mask = test_mask.nonzero().view(-1).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59193dfa-de4a-4544-9c8d-36dce938229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tensor(bill_train_mask.numpy(), './data/graph/bill_train_mask.y')\n",
    "save_tensor(bill_valid_mask.numpy(), './data/graph/bill_valid_mask.y')\n",
    "save_tensor(bill_test_mask.numpy(), './data/graph/bill_test_mask.y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70571d00-b735-4403-9623-599918e5d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_train_mask.numpy().shape, bill_valid_mask.numpy().shape, bill_test_mask.numpy().shape, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b82a264-89d0-4ffb-8584-27bb92998c77",
   "metadata": {},
   "source": [
    "## tweet mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc15b18-5762-4ef1-b45b-78994ce31f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = '2021-06-01'\n",
    "values = new_bh_tweet['date'].values\n",
    "train_mask = [compare_date(source_date, target_date) for source_date in values]\n",
    "train_mask = torch.LongTensor(train_mask)\n",
    "print(\"# train\", train_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a22ea7-6d33-46b4-b17c-2a2b093c1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = '2021-08-01'\n",
    "values = new_bh_tweet['date'].values\n",
    "valid_mask = [compare_date(source_date, target_date) for source_date in values]\n",
    "valid_mask = torch.LongTensor(valid_mask)\n",
    "valid_mask = valid_mask - train_mask\n",
    "print(\"# valid\", valid_mask.sum(), torch.unique(valid_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccce166-1e28-4d1c-ae2d-c34690be09b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = '2021-12-01'\n",
    "values = new_bh_tweet['date'].values\n",
    "test_mask = [compare_date(source_date, target_date) for source_date in values]\n",
    "test_mask = torch.LongTensor(test_mask)\n",
    "test_mask = test_mask - valid_mask - train_mask\n",
    "print(\"# test\", test_mask.sum(), torch.unique(test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d895a3-e749-43cb-8c03-5bd70dd46683",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_train_mask = train_mask.nonzero().view(-1).long()\n",
    "bh_valid_mask = valid_mask.nonzero().view(-1).long()\n",
    "bh_test_mask = test_mask.nonzero().view(-1).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee805c-f400-4d26-846a-b9531f5fc762",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tensor(bh_train_mask, './data/graph/train_mask.bh_tweet.x')\n",
    "save_tensor(bh_valid_mask, './data/graph/valid_mask.bh_tweet.x')\n",
    "save_tensor(bh_test_mask, './data/graph/test_mask.bh_tweet.x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d454148-f1f8-417b-9b19-ddd3b4d23844",
   "metadata": {
    "tags": []
   },
   "source": [
    "## member mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd8a67d-65ae-4c66-b5d9-f7df0f9f40bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_train_mask = torch.arange(len(member),dtype=torch.long)\n",
    "mem_valid_mask = torch.arange(len(member),dtype=torch.long)\n",
    "mem_test_mask = torch.arange(len(member),dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876e90e-43f3-4f23-8881-855d6ce4a5d6",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c66b3-1d59-41b7-b471-0ebfd57c5b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message types\n",
    "message_type = [\n",
    "    (\"bill\", \"keyword\", \"bill\"),\n",
    "    (\"president\", \"keyword\", \"bill\"),\n",
    "    (\"member\", \"propose\", \"bill\"),\n",
    "    \n",
    "    (\"member\", \"party\", \"member\"),\n",
    "    (\"president\", \"party\", \"member\"),\n",
    "    \n",
    "    (\"president\", \"keyword\", \"president\"),\n",
    "    (\"bill\", \"keyword\", \"president\")\n",
    "]\n",
    "\n",
    "# Dictionary of edge indices\n",
    "edge_index = {}\n",
    "edge_attr = {}\n",
    "message_type_index = [\n",
    "    bill_edges,\n",
    "    bh_bill_edges,\n",
    "    mem_bill_edges,\n",
    "    \n",
    "    mem_mem_edges,\n",
    "    bh_mem_edges,\n",
    "    \n",
    "    bh_edges,\n",
    "    bill_bh_edges\n",
    "]\n",
    "message_type_attr = [\n",
    "    bill_weights,\n",
    "    bh_bill_weights,\n",
    "    mem_bill_weights,\n",
    "    \n",
    "    mem_mem_weights,\n",
    "    bh_mem_weights,\n",
    "    \n",
    "    bh_weights,\n",
    "    bill_bh_weights\n",
    "]\n",
    "\n",
    "for mtyp, minx, mattr in zip(message_type, message_type_index, message_type_attr):\n",
    "    edge_index[mtyp] = minx.t().long()\n",
    "    edge_attr[mtyp] = mattr.unsqueeze(1).float()\n",
    "    print(mtyp, minx.size(), mattr.size())\n",
    "\n",
    "# Dictionary of node features\n",
    "node_feature = {}\n",
    "node_feature[\"bill\"] = bill_emb.float()\n",
    "node_feature[\"member\"] = mem_emb.float()\n",
    "node_feature[\"president\"] = bh_tweet_feat.float()\n",
    "\n",
    "# Dictionary of node labels\n",
    "node_label = {}\n",
    "node_label[\"bill\"] = bill_mem_vote.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da22f9e-c92b-436b-affd-44fe929395ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_idx = {\"bill\":bill_train_mask, \"member\":mem_train_mask, \"president\": bh_train_mask}\n",
    "val_idx = {\"bill\":bill_valid_mask, \"member\":mem_valid_mask, \"president\": bh_valid_mask}\n",
    "test_idx = {\"bill\":bill_test_mask, \"member\":mem_test_mask, \"president\": bh_test_mask}\n",
    "\n",
    "train_idx = {k: val.to(args['device']) for k, val in train_idx.items()}\n",
    "val_idx = {k: val.to(args['device']) for k, val in val_idx.items()}\n",
    "test_idx = {k: val.to(args['device']) for k, val in test_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af1ba7-1f77-4ba1-9947-c24c8e96a399",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_mem_vote[bill_train_mask].sum(), len(bill_mem_vote[bill_train_mask].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d208174-80c7-478f-9cc3-cdbb70d3231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_mem_vote[bill_valid_mask].sum(), len(bill_mem_vote[bill_valid_mask].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c1bc2e-32f0-4246-992f-254d93d2470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_mem_vote[bill_test_mask].sum(), len(bill_mem_vote[bill_test_mask].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d36a5a-2265-4952-8e1b-ae0288abaf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a deepsnap tensor backend HeteroGraph\n",
    "hetero_graph = HeteroGraph(\n",
    "    node_feature=node_feature,\n",
    "    node_label=node_label,\n",
    "    edge_index=edge_index,\n",
    "    edge_attr=edge_attr,\n",
    "    directed=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b7c7d0-82d7-44d4-8bb9-33ae91703480",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"KO-VOTE heterogeneous graph: {hetero_graph.num_nodes()} nodes, {hetero_graph.num_edges()} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce860c84-dbc7-4ee0-b81b-285412a83c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node feature and node label to device\n",
    "for key in hetero_graph.node_feature:\n",
    "    hetero_graph.node_feature[key] = hetero_graph.node_feature[key].to(args['device'])\n",
    "for key in hetero_graph.node_label:\n",
    "    hetero_graph.node_label[key] = hetero_graph.node_label[key].to(args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c20b8-7337-4421-8c85-c000be2e1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge_index to sparse tensor and to device\n",
    "for key, mtyp in zip(hetero_graph.edge_index, message_type):\n",
    "    source_node_type = mtyp[0]\n",
    "    target_node_type = mtyp[-1]\n",
    "    print(source_node_type, target_node_type)\n",
    "    edge_index = hetero_graph.edge_index[key]\n",
    "    print(edge_index)\n",
    "    adj = SparseTensor(row=edge_index[0], col=edge_index[1], \n",
    "                       sparse_sizes=(\n",
    "                           hetero_graph.num_nodes(source_node_type), \n",
    "                           hetero_graph.num_nodes(target_node_type)))\n",
    "    hetero_graph.edge_index[key] = adj.t().to(args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756c989-a258-411f-ab17-f7219d465996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_attr to device\n",
    "for key in hetero_graph.edge_attr:\n",
    "    hetero_graph.edge_attr[key] = hetero_graph.edge_attr[key].to(args['device'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5ecac1-a120-4c5e-9478-f2e3d34fd9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mtyp in message_type:\n",
    "    print(mtyp)\n",
    "#     print(hetero_graph.edge_attr[mtyp], hetero_graph.edge_attr[mtyp].dtype)\n",
    "    print(hetero_graph.edge_index[mtyp])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61dab7c-f952-4b71-8794-d10ba66f329f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056fdce5-c109-46d2-8253-2a2c837f0b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_weights(module):\n",
    "    if isinstance(module,nn.Linear):\n",
    "        nn.init.xavier_uniform_(module.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f7d42f-e8d3-4dde-9db7-5884cda31ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import deepsnap\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from deepsnap.hetero_gnn import forward_op\n",
    "from deepsnap.hetero_graph import HeteroGraph\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "\n",
    "class HeteroGNNConv(pyg_nn.MessagePassing):\n",
    "    def __init__(self, in_channels_src, in_channels_dst, out_channels):\n",
    "        super(HeteroGNNConv, self).__init__(aggr=\"mean\")\n",
    "\n",
    "        self.in_channels_src = in_channels_src\n",
    "        self.in_channels_dst = in_channels_dst\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.lin_dst = nn.Linear(self.in_channels_dst, self.out_channels)\n",
    "        self.lin_src = nn.Linear(self.in_channels_src, self.out_channels)\n",
    "        self.lin_update = nn.Linear(self.out_channels * 2, self.out_channels)\n",
    "        self.apply(_init_weights)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        node_feature_src,\n",
    "        node_feature_dst,\n",
    "        edge_index,\n",
    "        size=None,\n",
    "        res_n_id=None,\n",
    "    ):\n",
    "        return self.propagate(edge_index, size=size,\n",
    "                              node_feature_src=node_feature_src,\n",
    "                              node_feature_dst=node_feature_dst,\n",
    "                              res_n_id=res_n_id)\n",
    "\n",
    "    def message_and_aggregate(self, edge_index, node_feature_src):\n",
    "        return matmul(edge_index, node_feature_src, reduce='mean')\n",
    "\n",
    "    def update(self, aggr_out, node_feature_dst, res_n_id):\n",
    "        node_feature_dst = self.lin_dst(node_feature_dst)\n",
    "        aggr_out = self.lin_src(aggr_out)\n",
    "        concat_out = torch.cat((node_feature_dst, aggr_out), dim=-1)\n",
    "        aggr_out = self.lin_update(concat_out)\n",
    "        return aggr_out\n",
    "\n",
    "\n",
    "class HeteroGNNWrapperConv(deepsnap.hetero_gnn.HeteroConv):\n",
    "    def __init__(self, convs, args, hetero_graph, aggr):\n",
    "        super(HeteroGNNWrapperConv, self).__init__(convs, None)\n",
    "        self.aggr = aggr\n",
    "\n",
    "        # Map the index and message type\n",
    "        self.mapping = {}\n",
    "\n",
    "        # A numpy array that stores the final attention probability\n",
    "        \n",
    "        self.alpha = {}\n",
    "        self.attn_proj = {}\n",
    "\n",
    "        if self.aggr == \"attn\":           \n",
    "            self.attn_proj = nn.ModuleDict()\n",
    "            for node_type in hetero_graph.node_types:\n",
    "                self.attn_proj[node_type] = nn.Sequential(\n",
    "                    nn.Linear(args['hidden_size'], args['attn_size']),\n",
    "                    nn.Tanh(),\n",
    "                    # q_semantic_attention\n",
    "                    nn.Linear(args['attn_size'], 1, bias=False),\n",
    "                )\n",
    "                self.alpha[node_type] = None\n",
    "        self.apply(_init_weights)\n",
    "           \n",
    "    def reset_parameters(self):\n",
    "        super(HeteroConvWrapper, self).reset_parameters()\n",
    "        if self.aggr == \"attn\":\n",
    "            for layer in self.attn_proj.children():\n",
    "                layer.reset_parameters()\n",
    "\n",
    "    def forward(self, node_features, edge_indices):\n",
    "        # message_type 별로 conv.\n",
    "        message_type_emb = {}\n",
    "        for message_key, message_type in edge_indices.items():\n",
    "            src_type, edge_type, dst_type = message_key\n",
    "            node_feature_src = node_features[src_type]\n",
    "            node_feature_dst = node_features[dst_type]\n",
    "            edge_index = edge_indices[message_key]\n",
    "            message_type_emb[message_key] = (\n",
    "                self.convs[message_key](\n",
    "                    node_feature_src,\n",
    "                    node_feature_dst,\n",
    "                    edge_index,\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        # \n",
    "        node_emb = {dst: [] for _, _, dst in message_type_emb.keys()} \n",
    "        # example of elements of message_type_emb.keys()('bill', 'keyword', 'bill')\n",
    "        \n",
    "        mapping = {}\n",
    "        for (src, edge_type, dst), item in message_type_emb.items():\n",
    "            mapping[len(node_emb[dst])] = (src, edge_type, dst)\n",
    "            node_emb[dst].append(item)\n",
    "        \n",
    "        self.mapping = mapping\n",
    "        for node_type, embs in node_emb.items():\n",
    "            if len(embs) == 1:\n",
    "                node_emb[node_type] = embs[0]\n",
    "            else:\n",
    "                node_emb[node_type] = self.aggregate(embs, node_type)\n",
    "        return node_emb\n",
    "\n",
    "    def aggregate(self, xs, node_type):\n",
    "        if self.aggr == \"mean\":\n",
    "            out = torch.mean(torch.stack(xs), dim=0)\n",
    "            return out\n",
    "\n",
    "        elif self.aggr == \"attn\":\n",
    "            x = self.attn_proj[node_type](torch.stack(xs, dim=0))\n",
    "            x = torch.mean(x, dim=1)\n",
    "\n",
    "            self.alpha[node_type] = torch.softmax(x, dim=0)\n",
    "            self.alpha[node_type] = self.alpha[node_type].detach()\n",
    "\n",
    "            # apply the attention and update the h\n",
    "            out = torch.stack(xs, dim=0)\n",
    "            out = self.alpha[node_type].unsqueeze(-1) * out\n",
    "\n",
    "            out = torch.sum(out, dim=0)\n",
    "            return out\n",
    "\n",
    "\n",
    "def generate_convs(hetero_graph, conv, hidden_size, first_layer=False):\n",
    "    convs = {}\n",
    "    for m in hetero_graph.message_types:  # get all message types\n",
    "        if first_layer:  # in_channel_size = node_feature_size\n",
    "            num_node_feat_src = hetero_graph.num_node_features(m[0])\n",
    "            num_node_feat_dst = hetero_graph.num_node_features(m[-1])\n",
    "            convs[m] = conv(num_node_feat_src, num_node_feat_dst,\n",
    "                            hidden_size)\n",
    "        else:  # in_channel_size = hidden_size\n",
    "            convs[m] = conv(hidden_size, hidden_size, hidden_size)\n",
    "    return convs\n",
    "\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hetero_graph, args, aggr=\"mean\"):\n",
    "        super(HeteroGNN, self).__init__()\n",
    "        self.aggr = aggr\n",
    "        self.hidden_size = args['hidden_size']\n",
    "        num_labels = 2\n",
    "\n",
    "        convs1 = generate_convs(\n",
    "            hetero_graph, HeteroGNNConv, self.hidden_size, first_layer=True)\n",
    "        convs2 = generate_convs(\n",
    "            hetero_graph, HeteroGNNConv, self.hidden_size, first_layer=False)\n",
    "        \n",
    "        self.convs1 = HeteroGNNWrapperConv(convs1, args, hetero_graph, self.aggr)\n",
    "        self.convs2 = HeteroGNNWrapperConv(convs2, args, hetero_graph, self.aggr)\n",
    "\n",
    "        self.bns1 = nn.ModuleDict()\n",
    "        self.bns2 = nn.ModuleDict()\n",
    "        self.relus1 = nn.ModuleDict()\n",
    "        self.relus2 = nn.ModuleDict()\n",
    "\n",
    "        for node_type in hetero_graph.node_types:\n",
    "            self.bns1[node_type] = torch.nn.BatchNorm1d(\n",
    "                self.hidden_size, eps=1.0)\n",
    "            self.bns2[node_type] = torch.nn.BatchNorm1d(\n",
    "                self.hidden_size, eps=1.0)\n",
    "            self.relus1[node_type] = nn.LeakyReLU()\n",
    "            self.relus2[node_type] = nn.LeakyReLU()\n",
    "\n",
    "        self.clf = nn.Linear(self.hidden_size, num_labels)\n",
    "\n",
    "        self.apply(_init_weights)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, node_feature, edge_index):\n",
    "        x = node_feature\n",
    "\n",
    "        x = self.convs1(x, edge_index)\n",
    "        x = forward_op(x, self.bns1)\n",
    "        x = forward_op(x, self.relus1)\n",
    "\n",
    "        x = self.convs2(x, edge_index)\n",
    "        x = forward_op(x, self.bns2)\n",
    "        x = forward_op(x, self.relus2)\n",
    "\n",
    "        leg_emb = x['bill'] # (1105, 64)\n",
    "        mem_emb = x['member'] # (286, 64)\n",
    "        \n",
    "        leg_emb = leg_emb.unsqueeze(-1).permute(1, 0, 2) # torch.Size([64, 1105, 1])\n",
    "        mem_emb = mem_emb.unsqueeze(-1).permute(1, 2, 0) #  torch.Size([64, 1, 287])\n",
    "\n",
    "        \n",
    "        leg_mem = torch.bmm(leg_emb, mem_emb)  # torch.Size([64, 1105, 287])\n",
    "        leg_mem = leg_mem.permute(1, 2, 0)  # torch.Size([1105, 287, 64])\n",
    "        \n",
    "        vote = self.clf(leg_mem) # torch.Size([1105, 287, 2])\n",
    "        \n",
    "        return vote, mem_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4daabec-51d3-455e-94cb-68d7733d4f67",
   "metadata": {},
   "source": [
    "# Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091c4cb-094b-4d8c-969b-b66cf86b6a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(preds, y, indices, node_type):\n",
    "    loss = 0\n",
    "    \n",
    "    loss_func = F.cross_entropy\n",
    "\n",
    "    idx = indices[node_type]\n",
    "    preds = preds[idx]\n",
    "    true = y[node_type][idx]\n",
    "    loss += loss_func(preds, true)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d12fbf-f924-4781-8651-007fd864dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, hetero_graph, train_idx):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    preds, _ = model(hetero_graph.node_feature, hetero_graph.edge_index)\n",
    "    preds = torch.softmax(preds, dim=2)\n",
    "    preds = preds.permute(0, 2, 1)\n",
    "    loss = loss_fn(preds, hetero_graph.node_label, train_idx, node_type='bill')\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31fad3-c45a-43d5-a3dd-eabdd9b7d8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, graph, index, node_type='bill'):\n",
    "    model.eval()\n",
    "    idx = index[node_type]\n",
    "\n",
    "    preds, embed = model(graph.node_feature, graph.edge_index)\n",
    "    preds = preds[idx]\n",
    "    preds = torch.softmax(preds, dim=2)\n",
    "    preds = preds.permute(0, 2, 1)\n",
    "    \n",
    "    target = graph.node_label[node_type][idx]\n",
    "    \n",
    "    loss = F.cross_entropy(preds, target)\n",
    "    \n",
    "    label_np = target.cpu().numpy()\n",
    "    pred_np = torch.argmax(preds, dim=1).cpu().numpy()\n",
    "    \n",
    "    return loss.item(), pred_np, label_np, embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca565eb8-9c73-4d41-a0d8-4759180842b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(y_true, y_pred, index, node_type='bill'):\n",
    "    accs = []\n",
    "    pres = []\n",
    "    recs = []\n",
    "    f1s = []\n",
    "    num_samples = len(index[node_type])\n",
    "    for i in range(287):\n",
    "        pred = y_pred[:, i]\n",
    "        true = y_true[:, i]\n",
    "\n",
    "        accs.append(accuracy_score(y_pred=pred, y_true=true))\n",
    "        pres.append(precision_score(y_pred=pred, y_true=true, average='weighted'))\n",
    "        recs.append(recall_score(y_pred=pred, y_true=true, average='weighted'))\n",
    "        f1s.append(f1_score(y_pred=pred, y_true=true, average='weighted'))\n",
    "\n",
    "    return np.array(accs).mean(), np.array(pres).mean(), np.array(recs).mean(), np.array(f1s).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d33a5-71b9-4d3d-a443-9353ffb729b5",
   "metadata": {},
   "source": [
    "# Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6c01d4-131e-4306-957e-589062c13bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HeteroGNN(hetero_graph, args, aggr=\"mean\").to(args['device'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "\n",
    "best_model = None\n",
    "best_val = 0\n",
    "\n",
    "history = defaultdict(list)\n",
    "pbar = tqdm(range(args['epochs']))\n",
    "for epoch in range(args['epochs']):\n",
    "    loss = train(model, optimizer, hetero_graph, train_idx)\n",
    "    _, y_pred, y_true, _ = test(model, hetero_graph, train_idx)\n",
    "    history[\"loss\"].append(loss)\n",
    "    \n",
    "    train_acc, train_pre, train_rec, train_f1 = eval(y_pred=y_pred, y_true=y_true, index=train_idx)\n",
    "    history[\"f1_score\"].append(train_f1)\n",
    "    \n",
    "    val_loss, y_pred, y_true, _ = test(model, hetero_graph, val_idx)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    \n",
    "    val_acc, val_pre, val_rec, val_f1 = eval(y_pred=y_pred, y_true=y_true, index=val_idx)\n",
    "    history[\"val_f1_score\"].append(val_f1)\n",
    "    \n",
    "    _, y_pred, y_true, _ = test(model, hetero_graph, test_idx)\n",
    "    test_acc, test_pre, test_rec, test_f1 = eval(y_pred=y_pred, y_true=y_true, index=test_idx)\n",
    "    \n",
    "    if val_acc > best_val:\n",
    "        best_val = val_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    \n",
    "    pbar.set_description(\n",
    "        f\"Epoch {epoch + 1}: loss {round(loss, 5)}, \" +\n",
    "        f\"train acc {train_acc:.4f}%, \" +\n",
    "        f\"train macro {train_f1:.4f}%, \" +\n",
    "        f\"valid acc {val_acc:.4f}%, \" +\n",
    "        f\"valid macro {val_f1:.4f}%, \" +\n",
    "        f\"test acc {test_acc:.4f}%, \" +\n",
    "        f\"test macro {test_f1:.4f}%\"\n",
    "    )\n",
    "    pbar.update()\n",
    "pbar.close()\n",
    "\n",
    "_, y_pred, y_true, embed = test(best_model, hetero_graph, test_idx)\n",
    "print(eval(y_pred=y_pred, y_true=y_true, index=test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159b783d-d09c-49a2-917c-73d8083c8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history[\"loss\"])\n",
    "plt.plot(history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502444d-9859-49db-871c-fba23536b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history[\"f1_score\"])\n",
    "plt.plot(history[\"val_f1_score\"])\n",
    "plt.title(\"Macro F1 score\")\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee3e3c8-1a61-493d-90e4-c6ef660ff933",
   "metadata": {},
   "source": [
    "# Training! - Att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6be2d9-5889-4d98-a4fa-94ee443fa69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HeteroGNN(hetero_graph, args, aggr=\"attn\").to(args['device'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "\n",
    "best_model = None\n",
    "best_val = 0\n",
    "\n",
    "history = defaultdict(list)\n",
    "pbar = tqdm(range(args['epochs']))\n",
    "for epoch in range(args['epochs']):\n",
    "    loss = train(model, optimizer, hetero_graph, train_idx)\n",
    "    _, y_pred, y_true, _ = test(model, hetero_graph, train_idx)\n",
    "    history[\"loss\"].append(loss)\n",
    "    \n",
    "    train_acc, train_pre, train_rec, train_f1 = eval(y_pred=y_pred, y_true=y_true, index=train_idx)\n",
    "    history[\"f1_score\"].append(train_f1)\n",
    "    \n",
    "    val_loss, y_pred, y_true, _ = test(model, hetero_graph, val_idx)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    \n",
    "    val_acc, val_pre, val_rec, val_f1 = eval(y_pred=y_pred, y_true=y_true, index=val_idx)\n",
    "    history[\"val_f1_score\"].append(val_f1)\n",
    "    \n",
    "    _, y_pred, y_true, _ = test(model, hetero_graph, test_idx)\n",
    "    test_acc, test_pre, test_rec, test_f1 = eval(y_pred=y_pred, y_true=y_true, index=test_idx)\n",
    "    \n",
    "    if val_acc > best_val:\n",
    "        best_val = val_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    \n",
    "    pbar.set_description(\n",
    "        f\"Epoch {epoch + 1}: loss {round(loss, 5)}, \" +\n",
    "        f\"train acc {train_acc:.4f}%, \" +\n",
    "        f\"train macro {train_f1:.4f}%, \" +\n",
    "        f\"valid acc {val_acc:.4f}%, \" +\n",
    "        f\"valid macro {val_f1:.4f}%, \" +\n",
    "        f\"test acc {test_acc:.4f}%, \" +\n",
    "        f\"test macro {test_f1:.4f}%\"\n",
    "    )\n",
    "    pbar.update()\n",
    "pbar.close()\n",
    "\n",
    "_, y_pred, y_true, embed = test(best_model, hetero_graph, test_idx)\n",
    "print(eval(y_pred=y_pred, y_true=y_true, index=test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35a297a-d999-449d-a9a5-101647b0aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history[\"loss\"])\n",
    "plt.plot(history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a3e10-7b8a-4f45-adb9-b438a50b3d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history[\"f1_score\"])\n",
    "plt.plot(history[\"val_f1_score\"])\n",
    "plt.title(\"Macro F1 score\")\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70df9bd1-84db-4c06-8b66-6601a6dd19ef",
   "metadata": {},
   "source": [
    "# All Approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f3ec88-b33b-457a-bf33-b41d237eb91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_yes = np.ones_like(y_pred)\n",
    "print(eval(y_pred=all_yes, y_true=y_true, index=test_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2762206-9c3a-469d-8f86-d0de1862ef4d",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5cc9a3-5a36-4d02-95c6-220e8fbdf723",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_yes = np.random.randint(2, size=y_pred.shape[0] * y_pred.shape[1]).reshape(y_pred.shape[0], y_pred.shape[1])\n",
    "print(eval(y_pred=random_yes, y_true=y_true, index=test_idx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jiwon_py37",
   "language": "python",
   "name": "jiwon_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
